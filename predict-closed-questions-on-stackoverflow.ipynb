{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" # 1. Purpose of the project","metadata":{}},{"cell_type":"markdown","source":"This project will focus on data collected from stackoverflow. <br>\nUsing a DL model (BEART) I will try to predict if a question posted on the site is at risk of being closed. <br>\nQuestions that don't meet the stockoverfull standard are closed because they are irrelevant, poorly written, etc (about 6% of the questions posted). <br>\n\nMain parts:\n* Import libraries and load data from database\n* Data exploration\n* Data cleaning and preparation\n* Building our custom BERT model\n* Training\n* Evaluate the model results\n* Conclusions","metadata":{}},{"cell_type":"markdown","source":" # 2. Import libraries and load data from database","metadata":{"execution":{"iopub.status.busy":"2022-08-26T17:50:45.134620Z","iopub.execute_input":"2022-08-26T17:50:45.135077Z","iopub.status.idle":"2022-08-26T17:50:45.143821Z","shell.execute_reply.started":"2022-08-26T17:50:45.135044Z","shell.execute_reply":"2022-08-26T17:50:45.141757Z"}}},{"cell_type":"markdown","source":"### libraries","metadata":{}},{"cell_type":"code","source":"# libraries\n\n# data manipulation\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport re\nimport os\nfrom pathlib import Path  \nimport datetime\nimport seaborn as sn\n\n# import nlp Tokenizer/tools\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import words\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('omw-1.4')\nfrom transformers import BertTokenizer\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nfrom transformers import BertModel,DistilBertModel\nfrom transformers import AdamW\n\n# Evaluation and data prep\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\n# setup\npd.set_option('display.max_colwidth', None) # want to see all info in a cell","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-31T22:05:37.900429Z","iopub.execute_input":"2022-08-31T22:05:37.900813Z","iopub.status.idle":"2022-08-31T22:05:37.956122Z","shell.execute_reply.started":"2022-08-31T22:05:37.900784Z","shell.execute_reply":"2022-08-31T22:05:37.955296Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Loading data","metadata":{}},{"cell_type":"code","source":"# Loading and printing head\ndf_stock_over_raw = pd.read_csv(\"../input/predict-closed-questions-on-stack-overflow/train-sample.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:05:39.170908Z","iopub.execute_input":"2022-08-31T22:05:39.171223Z","iopub.status.idle":"2022-08-31T22:05:40.784802Z","shell.execute_reply.started":"2022-08-31T22:05:39.171198Z","shell.execute_reply":"2022-08-31T22:05:40.783943Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_stock_over_raw[0:3]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:05:40.786136Z","iopub.execute_input":"2022-08-31T22:05:40.786480Z","iopub.status.idle":"2022-08-31T22:05:40.800546Z","shell.execute_reply.started":"2022-08-31T22:05:40.786454Z","shell.execute_reply":"2022-08-31T22:05:40.799900Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"    PostId     PostCreationDate  OwnerUserId    OwnerCreationDate  \\\n0  6046168  05/18/2011 14:14:05       543315  09/17/2010 10:15:06   \n1  4873911  02/02/2011 11:30:10       465076  10/03/2010 09:30:58   \n2  3311559  07/22/2010 17:21:54       406143  07/22/2010 16:58:20   \n\n   ReputationAtPostCreation  OwnerUndeletedAnswerCountAtPostTime  \\\n0                         1                                    2   \n1                       192                                   24   \n2                         1                                    0   \n\n                                                                          Title  \\\n0  For Mongodb is it better to reference an object or use a natural String key?   \n1                        How to insert schemalocation in a xml document via DOM   \n2                                                       Too many lookup tables    \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      BodyMarkdown  \\\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I am building a corpus of indexed sentences in different languages. I have a collection of Languages which have both an ObjectId and the ISO code as a key. Is it better to use a reference to the Language collection or store a key like \"en\" or \"fr\"?\\r\\n\\r\\nI suppose it's a compromise between:\\r\\n\\r\\n - ease of referencing the Language\\r\\n - object in that collection\\r\\n - speed in doing queries where the sentence has a certain language\\r\\n - the size of the data on disk\\r\\n\\r\\nAny best practices that I should know of?   \n1  i create a xml document with JAXP and search a way to insert the schemalocation.\\r\\nAt the moment my application produces:\\r\\n\\r\\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\r\\n    <root>\\r\\n    ...\\r\\n    </root>\\r\\n\\r\\nBut i need:\\r\\n\\r\\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\r\\n    <root xmlns=\"namespaceURL\" \\r\\n    xmlns:xs=\"http://www.w3.org/2001/XMLSchema-instance\"\\r\\n    xs:schemaLocation=\"namespaceURL pathToMySchema.xsd\">\\r\\n    ...\\r\\n    </root>\\r\\n\\r\\nMy code:\\r\\n\\r\\n    StreamResult result = new StreamResult(writer);\\r\\n    Document doc = getDocument();\\r\\n\\r\\n    Transformer trans = transfac.newTransformer();\\r\\n    trans.setOutputProperty(OutputKeys.INDENT, \"yes\");\\r\\n    trans.setOutputProperty(OutputKeys.METHOD, \"xml\");\\r\\n    trans.setOutputProperty(OutputKeys.VERSION, \"1.0\");\\r\\n    trans.setOutputProperty(OutputKeys.ENCODING, \"UTF-8\");\\r\\n\\r\\n    DOMSource source = new DOMSource(depl.getAsElement(doc));\\r\\n    trans.transform(source, result);\\r\\n\\r\\n\\r\\nThanks for your time,  \\r\\nKasten   \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               What are the adverse effects of having too many lookup tables in the database?\\r\\n\\r\\n I have to incorportate too many Enumerations, based on the applications. \\r\\n\\r\\nWhat would experts advice?   \n\n         Tag1             Tag2   Tag3 Tag4 Tag5 PostClosedDate OpenStatus  \n0     mongodb              NaN    NaN  NaN  NaN            NaN       open  \n1         dom              xsd   jaxp  NaN  NaN            NaN       open  \n2  sql-server  database-design  enums  NaN  NaN            NaN       open  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PostId</th>\n      <th>PostCreationDate</th>\n      <th>OwnerUserId</th>\n      <th>OwnerCreationDate</th>\n      <th>ReputationAtPostCreation</th>\n      <th>OwnerUndeletedAnswerCountAtPostTime</th>\n      <th>Title</th>\n      <th>BodyMarkdown</th>\n      <th>Tag1</th>\n      <th>Tag2</th>\n      <th>Tag3</th>\n      <th>Tag4</th>\n      <th>Tag5</th>\n      <th>PostClosedDate</th>\n      <th>OpenStatus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6046168</td>\n      <td>05/18/2011 14:14:05</td>\n      <td>543315</td>\n      <td>09/17/2010 10:15:06</td>\n      <td>1</td>\n      <td>2</td>\n      <td>For Mongodb is it better to reference an object or use a natural String key?</td>\n      <td>I am building a corpus of indexed sentences in different languages. I have a collection of Languages which have both an ObjectId and the ISO code as a key. Is it better to use a reference to the Language collection or store a key like \"en\" or \"fr\"?\\r\\n\\r\\nI suppose it's a compromise between:\\r\\n\\r\\n - ease of referencing the Language\\r\\n - object in that collection\\r\\n - speed in doing queries where the sentence has a certain language\\r\\n - the size of the data on disk\\r\\n\\r\\nAny best practices that I should know of?</td>\n      <td>mongodb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4873911</td>\n      <td>02/02/2011 11:30:10</td>\n      <td>465076</td>\n      <td>10/03/2010 09:30:58</td>\n      <td>192</td>\n      <td>24</td>\n      <td>How to insert schemalocation in a xml document via DOM</td>\n      <td>i create a xml document with JAXP and search a way to insert the schemalocation.\\r\\nAt the moment my application produces:\\r\\n\\r\\n    &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\r\\n    &lt;root&gt;\\r\\n    ...\\r\\n    &lt;/root&gt;\\r\\n\\r\\nBut i need:\\r\\n\\r\\n    &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\r\\n    &lt;root xmlns=\"namespaceURL\" \\r\\n    xmlns:xs=\"http://www.w3.org/2001/XMLSchema-instance\"\\r\\n    xs:schemaLocation=\"namespaceURL pathToMySchema.xsd\"&gt;\\r\\n    ...\\r\\n    &lt;/root&gt;\\r\\n\\r\\nMy code:\\r\\n\\r\\n    StreamResult result = new StreamResult(writer);\\r\\n    Document doc = getDocument();\\r\\n\\r\\n    Transformer trans = transfac.newTransformer();\\r\\n    trans.setOutputProperty(OutputKeys.INDENT, \"yes\");\\r\\n    trans.setOutputProperty(OutputKeys.METHOD, \"xml\");\\r\\n    trans.setOutputProperty(OutputKeys.VERSION, \"1.0\");\\r\\n    trans.setOutputProperty(OutputKeys.ENCODING, \"UTF-8\");\\r\\n\\r\\n    DOMSource source = new DOMSource(depl.getAsElement(doc));\\r\\n    trans.transform(source, result);\\r\\n\\r\\n\\r\\nThanks for your time,  \\r\\nKasten</td>\n      <td>dom</td>\n      <td>xsd</td>\n      <td>jaxp</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3311559</td>\n      <td>07/22/2010 17:21:54</td>\n      <td>406143</td>\n      <td>07/22/2010 16:58:20</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Too many lookup tables</td>\n      <td>What are the adverse effects of having too many lookup tables in the database?\\r\\n\\r\\n I have to incorportate too many Enumerations, based on the applications. \\r\\n\\r\\nWhat would experts advice?</td>\n      <td>sql-server</td>\n      <td>database-design</td>\n      <td>enums</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>open</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":" # 3. Data exploration","metadata":{"execution":{"iopub.status.busy":"2022-08-26T17:57:56.413030Z","iopub.execute_input":"2022-08-26T17:57:56.414561Z","iopub.status.idle":"2022-08-26T17:57:56.421258Z","shell.execute_reply.started":"2022-08-26T17:57:56.414492Z","shell.execute_reply":"2022-08-26T17:57:56.419759Z"}}},{"cell_type":"markdown","source":"### Lets take a look at the diffrent columns","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:37:14.305483Z","iopub.execute_input":"2022-08-30T07:37:14.306161Z","iopub.status.idle":"2022-08-30T07:37:14.311425Z","shell.execute_reply.started":"2022-08-30T07:37:14.306117Z","shell.execute_reply":"2022-08-30T07:37:14.310136Z"}}},{"cell_type":"code","source":"df_stock_over_raw.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:05:42.212027Z","iopub.execute_input":"2022-08-31T22:05:42.212545Z","iopub.status.idle":"2022-08-31T22:05:42.294278Z","shell.execute_reply.started":"2022-08-31T22:05:42.212516Z","shell.execute_reply":"2022-08-31T22:05:42.293294Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 140272 entries, 0 to 140271\nData columns (total 15 columns):\n #   Column                               Non-Null Count   Dtype \n---  ------                               --------------   ----- \n 0   PostId                               140272 non-null  int64 \n 1   PostCreationDate                     140272 non-null  object\n 2   OwnerUserId                          140272 non-null  int64 \n 3   OwnerCreationDate                    140272 non-null  object\n 4   ReputationAtPostCreation             140272 non-null  int64 \n 5   OwnerUndeletedAnswerCountAtPostTime  140272 non-null  int64 \n 6   Title                                140272 non-null  object\n 7   BodyMarkdown                         140272 non-null  object\n 8   Tag1                                 140262 non-null  object\n 9   Tag2                                 113021 non-null  object\n 10  Tag3                                 75914 non-null   object\n 11  Tag4                                 39650 non-null   object\n 12  Tag5                                 15714 non-null   object\n 13  PostClosedDate                       70136 non-null   object\n 14  OpenStatus                           140272 non-null  object\ndtypes: int64(4), object(11)\nmemory usage: 16.1+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We have 140,272 data points, lets see how many are closed vs open.","metadata":{}},{"cell_type":"markdown","source":"### Lets take a look at the ratio of diffrent status values","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:37:14.305483Z","iopub.execute_input":"2022-08-30T07:37:14.306161Z","iopub.status.idle":"2022-08-30T07:37:14.311425Z","shell.execute_reply.started":"2022-08-30T07:37:14.306117Z","shell.execute_reply":"2022-08-30T07:37:14.310136Z"}}},{"cell_type":"code","source":"df_stock_over_raw.groupby(['OpenStatus']).count()['PostId']/140272","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:06:05.879602Z","iopub.execute_input":"2022-08-31T22:06:05.879958Z","iopub.status.idle":"2022-08-31T22:06:06.001422Z","shell.execute_reply.started":"2022-08-31T22:06:05.879928Z","shell.execute_reply":"2022-08-31T22:06:06.000463Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"OpenStatus\nnot a real question    0.219495\nnot constructive       0.111633\noff topic              0.124971\nopen                   0.500000\ntoo localized          0.043900\nName: PostId, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# Lets see the status events by %\nstock_over_status_split = df_stock_over_raw.groupby(['OpenStatus']).count()['PostId']/140272\nstock_over_status_split.sort_values(ascending=False).plot(kind=\"bar\")\nprint('Question status %')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:06:06.299973Z","iopub.execute_input":"2022-08-31T22:06:06.300755Z","iopub.status.idle":"2022-08-31T22:06:06.581176Z","shell.execute_reply.started":"2022-08-31T22:06:06.300725Z","shell.execute_reply":"2022-08-31T22:06:06.580585Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Question status %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"We see that about half is open in our sample.","metadata":{"execution":{"iopub.status.busy":"2022-08-26T18:25:25.059360Z","iopub.execute_input":"2022-08-26T18:25:25.059785Z","iopub.status.idle":"2022-08-26T18:25:25.064885Z","shell.execute_reply.started":"2022-08-26T18:25:25.059753Z","shell.execute_reply":"2022-08-26T18:25:25.063892Z"}}},{"cell_type":"code","source":"# Lets see if we have more features with a small amount of values\ndf_stock_over_raw.nunique().sort_values()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:06:07.508120Z","iopub.execute_input":"2022-08-31T22:06:07.508969Z","iopub.status.idle":"2022-08-31T22:06:07.972278Z","shell.execute_reply.started":"2022-08-31T22:06:07.508940Z","shell.execute_reply":"2022-08-31T22:06:07.971670Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"OpenStatus                                  5\nOwnerUndeletedAnswerCountAtPostTime       965\nTag1                                     5209\nReputationAtPostCreation                 6423\nTag5                                     7605\nTag2                                     9292\nTag4                                    10027\nTag3                                    11080\nPostClosedDate                          70070\nOwnerCreationDate                       94149\nOwnerUserId                             94215\nPostCreationDate                       140118\nTitle                                  140192\nBodyMarkdown                           140270\nPostId                                 140272\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# lets see the first 3 headers/body\nfor i in range(1):\n    print('Question number {}: \\n\\nheader is: \\n{}\\nbody: \\n{} \\n'.format(i+1,df_stock_over_raw['Title'].iloc[i],df_stock_over_raw['BodyMarkdown'].iloc[i]))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:06:09.667560Z","iopub.execute_input":"2022-08-31T22:06:09.667898Z","iopub.status.idle":"2022-08-31T22:06:09.673340Z","shell.execute_reply.started":"2022-08-31T22:06:09.667871Z","shell.execute_reply":"2022-08-31T22:06:09.672296Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Question number 1: \n\nheader is: \nFor Mongodb is it better to reference an object or use a natural String key?\nbody: \nI am building a corpus of indexed sentences in different languages. I have a collection of Languages which have both an ObjectId and the ISO code as a key. Is it better to use a reference to the Language collection or store a key like \"en\" or \"fr\"?\n\nI suppose it's a compromise between:\n\n - ease of referencing the Language\n - object in that collection\n - speed in doing queries where the sentence has a certain language\n - the size of the data on disk\n\nAny best practices that I should know of? \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Lets take a look at the amount of words we have in the first 95% data points","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:37:14.305483Z","iopub.execute_input":"2022-08-30T07:37:14.306161Z","iopub.status.idle":"2022-08-30T07:37:14.311425Z","shell.execute_reply.started":"2022-08-30T07:37:14.306117Z","shell.execute_reply":"2022-08-30T07:37:14.310136Z"}}},{"cell_type":"code","source":"full_text = df_stock_over_raw['Title'] + df_stock_over_raw['BodyMarkdown']\nfull_text_count = full_text.str.split().str.len()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:06:10.542658Z","iopub.execute_input":"2022-08-31T22:06:10.543199Z","iopub.status.idle":"2022-08-31T22:06:12.358775Z","shell.execute_reply.started":"2022-08-31T22:06:10.543169Z","shell.execute_reply":"2022-08-31T22:06:12.358035Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"full_text_count[full_text_count<full_text_count.quantile(0.95)].hist(bins=10)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:06:12.360101Z","iopub.execute_input":"2022-08-31T22:06:12.360554Z","iopub.status.idle":"2022-08-31T22:06:12.821866Z","shell.execute_reply.started":"2022-08-31T22:06:12.360523Z","shell.execute_reply":"2022-08-31T22:06:12.820606Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"So we can easily see that most of our data is below BERT's 512 tolkens limit, thats good!","metadata":{}},{"cell_type":"markdown","source":"# 4. Data cleaning and preparation","metadata":{}},{"cell_type":"code","source":"# Lets start with creating a new column for combining head and body\ndf_stock_over_raw['text'] = df_stock_over_raw['Title'] + ' ' +df_stock_over_raw['BodyMarkdown']","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:23:46.929908Z","iopub.execute_input":"2022-08-31T19:23:46.930475Z","iopub.status.idle":"2022-08-31T19:23:47.017629Z","shell.execute_reply.started":"2022-08-31T19:23:46.930436Z","shell.execute_reply":"2022-08-31T19:23:47.016214Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# looks good!\ndf_stock_over_raw[0:1][['text','BodyMarkdown','Title']]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:23:47.019050Z","iopub.execute_input":"2022-08-31T19:23:47.019505Z","iopub.status.idle":"2022-08-31T19:23:47.031388Z","shell.execute_reply.started":"2022-08-31T19:23:47.019468Z","shell.execute_reply":"2022-08-31T19:23:47.030256Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n0  For Mongodb is it better to reference an object or use a natural String key? I am building a corpus of indexed sentences in different languages. I have a collection of Languages which have both an ObjectId and the ISO code as a key. Is it better to use a reference to the Language collection or store a key like \"en\" or \"fr\"?\\r\\n\\r\\nI suppose it's a compromise between:\\r\\n\\r\\n - ease of referencing the Language\\r\\n - object in that collection\\r\\n - speed in doing queries where the sentence has a certain language\\r\\n - the size of the data on disk\\r\\n\\r\\nAny best practices that I should know of?   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 BodyMarkdown  \\\n0  I am building a corpus of indexed sentences in different languages. I have a collection of Languages which have both an ObjectId and the ISO code as a key. Is it better to use a reference to the Language collection or store a key like \"en\" or \"fr\"?\\r\\n\\r\\nI suppose it's a compromise between:\\r\\n\\r\\n - ease of referencing the Language\\r\\n - object in that collection\\r\\n - speed in doing queries where the sentence has a certain language\\r\\n - the size of the data on disk\\r\\n\\r\\nAny best practices that I should know of?   \n\n                                                                          Title  \n0  For Mongodb is it better to reference an object or use a natural String key?  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>BodyMarkdown</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>For Mongodb is it better to reference an object or use a natural String key? I am building a corpus of indexed sentences in different languages. I have a collection of Languages which have both an ObjectId and the ISO code as a key. Is it better to use a reference to the Language collection or store a key like \"en\" or \"fr\"?\\r\\n\\r\\nI suppose it's a compromise between:\\r\\n\\r\\n - ease of referencing the Language\\r\\n - object in that collection\\r\\n - speed in doing queries where the sentence has a certain language\\r\\n - the size of the data on disk\\r\\n\\r\\nAny best practices that I should know of?</td>\n      <td>I am building a corpus of indexed sentences in different languages. I have a collection of Languages which have both an ObjectId and the ISO code as a key. Is it better to use a reference to the Language collection or store a key like \"en\" or \"fr\"?\\r\\n\\r\\nI suppose it's a compromise between:\\r\\n\\r\\n - ease of referencing the Language\\r\\n - object in that collection\\r\\n - speed in doing queries where the sentence has a certain language\\r\\n - the size of the data on disk\\r\\n\\r\\nAny best practices that I should know of?</td>\n      <td>For Mongodb is it better to reference an object or use a natural String key?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Lets create a new df with only the relavent columns\ndf_for_bert = df_stock_over_raw[['text','OpenStatus']]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:23:47.033206Z","iopub.execute_input":"2022-08-31T19:23:47.033915Z","iopub.status.idle":"2022-08-31T19:23:47.113895Z","shell.execute_reply.started":"2022-08-31T19:23:47.033871Z","shell.execute_reply":"2022-08-31T19:23:47.112911Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Lets change the names of our text and lables\ndf_for_bert.columns = ['text','label']\ndf_for_bert.columns","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:23:47.117422Z","iopub.execute_input":"2022-08-31T19:23:47.117756Z","iopub.status.idle":"2022-08-31T19:23:47.128078Z","shell.execute_reply.started":"2022-08-31T19:23:47.117727Z","shell.execute_reply":"2022-08-31T19:23:47.126768Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Index(['text', 'label'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"# mapping the category name to numbers\n\nlabels_status = {'open': 0, \n           'too localized': 1,\n           'not a real question': 2,\n           'off topic': 3,\n           'not constructive':4}\n\ndf_for_bert['label'] = df_for_bert['label'].map(labels_status)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:23:47.130433Z","iopub.execute_input":"2022-08-31T19:23:47.131232Z","iopub.status.idle":"2022-08-31T19:23:47.153127Z","shell.execute_reply.started":"2022-08-31T19:23:47.131195Z","shell.execute_reply":"2022-08-31T19:23:47.152184Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  if __name__ == \"__main__\":\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Split train dataset into train, validation and test sets","metadata":{}},{"cell_type":"code","source":"train_text, temp_text, train_labels, temp_labels = train_test_split(df_for_bert['text'], df_for_bert['label'], \n                                                                    random_state=42, \n                                                                    test_size=0.3, \n                                                                    stratify=df_for_bert['label'])\n\n# we will use temp_text and temp_labels to create validation and test set\nval_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n                                                                random_state=42, \n                                                                test_size=0.5, \n                                                                stratify=temp_labels)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:23:47.161374Z","iopub.execute_input":"2022-08-31T19:23:47.162113Z","iopub.status.idle":"2022-08-31T19:23:47.195338Z","shell.execute_reply.started":"2022-08-31T19:23:47.162057Z","shell.execute_reply":"2022-08-31T19:23:47.194238Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Import BERT Model and BERT Tokenizer","metadata":{}},{"cell_type":"code","source":"# import BERT model\nbert = BertModel.from_pretrained('bert-base-uncased')\n\n# Loading the BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:23:47.196881Z","iopub.execute_input":"2022-08-31T19:23:47.197223Z","iopub.status.idle":"2022-08-31T19:24:13.311763Z","shell.execute_reply.started":"2022-08-31T19:23:47.197190Z","shell.execute_reply":"2022-08-31T19:24:13.310675Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"550c7cef4b164fecb4e9fc1778083b17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f535c68825a4deaab9455c5549480dd"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e9292e5747c46718c81a956e3151b48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3e3e595324d4b4eb321f8bba73fe645"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Preparing the tokenizers","metadata":{}},{"cell_type":"code","source":"# setting the maximum tokens possible for BERT 512 or less if GPU space isnt sufficient\nmax_seq_len = 512\n\n# tokenize and encode sequences in the training set\ntokens_train = tokenizer.batch_encode_plus(\n    train_text.tolist(),\n    max_length = max_seq_len,\n    pad_to_max_length=True,\n    truncation=True,\n    return_token_type_ids=False\n)\n\n# tokenize and encode sequences in the validation set\ntokens_val = tokenizer.batch_encode_plus(\n    val_text.tolist(),\n    max_length = max_seq_len,\n    pad_to_max_length=True,\n    truncation=True,\n    return_token_type_ids=False\n)\n\n# tokenize and encode sequences in the test set\ntokens_test = tokenizer.batch_encode_plus(\n    test_text.tolist(),\n    max_length = max_seq_len,\n    pad_to_max_length=True,\n    truncation=True,\n    return_token_type_ids=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:32:04.616746Z","iopub.execute_input":"2022-08-31T20:32:04.617411Z","iopub.status.idle":"2022-08-31T20:35:49.749058Z","shell.execute_reply.started":"2022-08-31T20:32:04.617374Z","shell.execute_reply":"2022-08-31T20:35:49.748055Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Casting type to torch tensor","metadata":{}},{"cell_type":"code","source":"# Train set\ntrain_seq = torch.tensor(tokens_train['input_ids'])\ntrain_y = torch.tensor(train_labels.tolist())\ntrain_mask = torch.tensor(tokens_train['attention_mask'])\n\n# Validation set\nval_seq = torch.tensor(tokens_val['input_ids'])\nval_y = torch.tensor(val_labels.tolist())\nval_mask = torch.tensor(tokens_val['attention_mask'])\n\n# Test set\ntest_seq = torch.tensor(tokens_test['input_ids'])\ntest_y = torch.tensor(test_labels.tolist())\ntest_mask = torch.tensor(tokens_test['attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:35:49.752561Z","iopub.execute_input":"2022-08-31T20:35:49.752972Z","iopub.status.idle":"2022-08-31T20:35:52.726959Z","shell.execute_reply.started":"2022-08-31T20:35:49.752944Z","shell.execute_reply":"2022-08-31T20:35:52.725914Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### Creating DataLoaders","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n#define a batch size\nbatch_size = 32\n\n# wrap tensors\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\n\n# sampler for sampling the data during training\ntrain_sampler = RandomSampler(train_data)\n\n# dataLoader for train set\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# wrap tensors\nval_data = TensorDataset(val_seq, val_mask, val_y)\n\n# sampler for sampling the data during training\nval_sampler = SequentialSampler(val_data)\n\n# dataLoader for validation set\nval_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:35:52.728498Z","iopub.execute_input":"2022-08-31T20:35:52.728947Z","iopub.status.idle":"2022-08-31T20:35:52.746853Z","shell.execute_reply.started":"2022-08-31T20:35:52.728905Z","shell.execute_reply":"2022-08-31T20:35:52.745650Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# 5. Building our custom BERT model","metadata":{}},{"cell_type":"markdown","source":"### Class creation","metadata":{}},{"cell_type":"code","source":"'''\nClass BERT_Arch is based on pre-trained model BERT, its designed to output five classes\n\n'''\n\nclass BERT_Arch(nn.Module):\n\n    def __init__(self, bert):\n        \n      \n        super(BERT_Arch, self).__init__()\n\n        self.bert = bert \n      \n        # dropout layer\n        self.dropout = nn.Dropout(0.1)\n      \n       # relu activation function\n        self.relu =  nn.ReLU()\n\n        # dense layer 1\n        self.fc1 = nn.Linear(768,512)\n      \n        # dense layer 2 (Output layer)\n        self.fc2 = nn.Linear(512,5)\n\n        #softmax activation function\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    #define the forward pass\n    def forward(self, sent_id, mask):\n        \n\n        #pass the inputs to the model  \n        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n        \n        x = self.fc1(cls_hs)\n\n        x = self.relu(x)\n\n        x = self.dropout(x)\n\n        # output layer\n        x = self.fc2(x)\n      \n        # apply softmax activation\n        x = self.softmax(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:35:52.749642Z","iopub.execute_input":"2022-08-31T20:35:52.751355Z","iopub.status.idle":"2022-08-31T20:35:52.761672Z","shell.execute_reply.started":"2022-08-31T20:35:52.751318Z","shell.execute_reply":"2022-08-31T20:35:52.760527Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Instantiation the model and transfering to GPU mode","metadata":{"execution":{"iopub.status.busy":"2022-08-30T22:43:16.419639Z","iopub.execute_input":"2022-08-30T22:43:16.420123Z","iopub.status.idle":"2022-08-30T22:43:16.428941Z","shell.execute_reply.started":"2022-08-30T22:43:16.420078Z","shell.execute_reply":"2022-08-30T22:43:16.427769Z"}}},{"cell_type":"code","source":"# specify GPU\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = BERT_Arch(bert)\n\n# push the model to GPU\nmodel = model.to(device)\n\n\n# define the optimizer\noptimizer = AdamW(model.parameters(), lr = 1e-3)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:35:52.763201Z","iopub.execute_input":"2022-08-31T20:35:52.763567Z","iopub.status.idle":"2022-08-31T20:35:52.787225Z","shell.execute_reply.started":"2022-08-31T20:35:52.763522Z","shell.execute_reply":"2022-08-31T20:35:52.785624Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Creating the train Class","metadata":{}},{"cell_type":"code","source":"'''\nFunction for train the model\n\nInput:  None\n\nOutput: \n        avg_loss (Float) - the average loss\n        total_preds (List) - List of model predictions\n'''\n\n# function to train the model\ndef train():\n  \n    model.train()\n\n    total_loss, total_accuracy = 0, 0\n  \n    # empty list to save model predictions\n    total_preds=[]\n  \n    # iterate over batches\n    for step,batch in enumerate(train_dataloader):\n    \n        # progress update after every 50 batches.\n        if step % 50 == 0 and not step == 0:\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n\n        # push the batch to gpu\n        batch = [r.to(device) for r in batch]\n \n        sent_id, mask, labels = batch\n\n        # clear previously calculated gradients \n        model.zero_grad()        \n\n        # get model predictions for the current batch\n        preds = model(sent_id, mask)\n\n        # compute the loss between actual and predicted values\n        loss = cross_entropy(preds, labels)\n\n        # add on to the total loss\n        total_loss = total_loss + loss.item()\n\n        # backward pass to calculate the gradients\n        loss.backward()\n\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # update parameters\n        optimizer.step()\n  \n        # model predictions are stored on GPU. So, push it to CPU\n        preds=preds.detach().cpu().numpy()\n\n        # append the model predictions\n        total_preds.append(preds)\n    # compute the training loss of the epoch\n    avg_loss = total_loss / len(train_dataloader)\n  \n    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n    # reshape the predictions in form of (number of samples, no. of classes)\n    total_preds  = np.concatenate(total_preds, axis=0)\n\n    #returns the loss and predictions\n    return avg_loss, total_preds","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:28:11.388295Z","iopub.execute_input":"2022-08-31T19:28:11.388683Z","iopub.status.idle":"2022-08-31T19:28:11.399881Z","shell.execute_reply.started":"2022-08-31T19:28:11.388646Z","shell.execute_reply":"2022-08-31T19:28:11.398549Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Creating the evaluate calss","metadata":{}},{"cell_type":"code","source":"'''\nFunction for evaluating the model\n\nInput:  None\n\nOutput: \n        avg_loss (Float) - the average loss\n        total_preds (List) - List of model predictions\n'''\n\ndef evaluate():\n    \n    print(\"\\nEvaluating...\")\n    \n    # deactivate dropout layers\n    model.eval()\n\n    total_loss, total_accuracy = 0, 0\n  \n    # empty list to save the model predictions\n    total_preds = []\n\n    # iterate over batches\n    for step,batch in enumerate(val_dataloader):\n    \n        # Progress update every 50 batches.\n        if step % 50 == 0 and not step == 0:\n\n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n    \n\n    # push the batch to gpu\n    batch = [t.to(device) for t in batch]\n\n    sent_id, mask, labels = batch\n\n    # deactivate autograd\n    with torch.no_grad():\n        \n        # model predictions\n        preds = model(sent_id, mask)\n\n        # compute the validation loss between actual and predicted values\n        loss = cross_entropy(preds,labels)\n\n        total_loss = total_loss + loss.item()\n\n        preds = preds.detach().cpu().numpy()\n\n        total_preds.append(preds)\n    # compute the validation loss of the epoch\n    avg_loss = total_loss / len(val_dataloader) \n\n    # reshape the predictions in form of (number of samples, no. of classes)\n    total_preds  = np.concatenate(total_preds, axis=0)\n\n    return avg_loss, total_preds","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:28:11.401195Z","iopub.execute_input":"2022-08-31T19:28:11.402315Z","iopub.status.idle":"2022-08-31T19:28:11.419472Z","shell.execute_reply.started":"2022-08-31T19:28:11.402279Z","shell.execute_reply":"2022-08-31T19:28:11.418270Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# 6. Training","metadata":{}},{"cell_type":"markdown","source":"### Freeze BERT Parameters","metadata":{}},{"cell_type":"code","source":"# freeze all the parameters\nfor param in bert.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-08-31T18:43:49.117678Z","iopub.execute_input":"2022-08-31T18:43:49.118497Z","iopub.status.idle":"2022-08-31T18:43:49.131324Z","shell.execute_reply.started":"2022-08-31T18:43:49.118461Z","shell.execute_reply":"2022-08-31T18:43:49.130371Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Setting up the loss function and number of epochs","metadata":{}},{"cell_type":"code","source":"# loss function\ncross_entropy  = nn.NLLLoss() \n\n# number of training epochs\nepochs = 3","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:28:11.420940Z","iopub.execute_input":"2022-08-31T19:28:11.421305Z","iopub.status.idle":"2022-08-31T19:28:11.433451Z","shell.execute_reply.started":"2022-08-31T19:28:11.421270Z","shell.execute_reply":"2022-08-31T19:28:11.432433Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Training and tarning/validation losses","metadata":{}},{"cell_type":"code","source":"# set initial loss to infinite\nbest_valid_loss = float('inf')\nmodel = model.to(device)\n\n# lists for validation and traning loesses\ntrain_losses=[]\nvalid_losses=[]\n\n#for each epoch\nfor epoch in range(epochs):\n     \n    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n    \n    #train model\n    train_loss, _ = train()\n    \n    #evaluate model\n    valid_loss, _ = evaluate()\n    \n    #save the best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'saved_weights.pt')\n    \n    # append training and validation loss\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    \n    print(f'\\nTraining Loss: {train_loss:.3f}')\n    print(f'Validation Loss: {valid_loss:.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T19:28:11.435275Z","iopub.execute_input":"2022-08-31T19:28:11.435660Z","iopub.status.idle":"2022-08-31T20:18:30.876213Z","shell.execute_reply.started":"2022-08-31T19:28:11.435625Z","shell.execute_reply":"2022-08-31T20:18:30.874768Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\n Epoch 1 / 3\n  Batch    50  of  1,094.\n  Batch   100  of  1,094.\n  Batch   150  of  1,094.\n  Batch   200  of  1,094.\n  Batch   250  of  1,094.\n  Batch   300  of  1,094.\n  Batch   350  of  1,094.\n  Batch   400  of  1,094.\n  Batch   450  of  1,094.\n  Batch   500  of  1,094.\n  Batch   550  of  1,094.\n  Batch   600  of  1,094.\n  Batch   650  of  1,094.\n  Batch   700  of  1,094.\n  Batch   750  of  1,094.\n  Batch   800  of  1,094.\n  Batch   850  of  1,094.\n  Batch   900  of  1,094.\n  Batch   950  of  1,094.\n  Batch 1,000  of  1,094.\n  Batch 1,050  of  1,094.\n\nEvaluating...\n  Batch    50  of    235.\n  Batch   100  of    235.\n  Batch   150  of    235.\n  Batch   200  of    235.\n\nTraining Loss: 1.341\nValidation Loss: 0.006\n\n Epoch 2 / 3\n  Batch    50  of  1,094.\n  Batch   100  of  1,094.\n  Batch   150  of  1,094.\n  Batch   200  of  1,094.\n  Batch   250  of  1,094.\n  Batch   300  of  1,094.\n  Batch   350  of  1,094.\n  Batch   400  of  1,094.\n  Batch   450  of  1,094.\n  Batch   500  of  1,094.\n  Batch   550  of  1,094.\n  Batch   600  of  1,094.\n  Batch   650  of  1,094.\n  Batch   700  of  1,094.\n  Batch   750  of  1,094.\n  Batch   800  of  1,094.\n  Batch   850  of  1,094.\n  Batch   900  of  1,094.\n  Batch   950  of  1,094.\n  Batch 1,000  of  1,094.\n  Batch 1,050  of  1,094.\n\nEvaluating...\n  Batch    50  of    235.\n  Batch   100  of    235.\n  Batch   150  of    235.\n  Batch   200  of    235.\n\nTraining Loss: 1.330\nValidation Loss: 0.006\n\n Epoch 3 / 3\n  Batch    50  of  1,094.\n  Batch   100  of  1,094.\n  Batch   150  of  1,094.\n  Batch   200  of  1,094.\n  Batch   250  of  1,094.\n  Batch   300  of  1,094.\n  Batch   350  of  1,094.\n  Batch   400  of  1,094.\n  Batch   450  of  1,094.\n  Batch   500  of  1,094.\n  Batch   550  of  1,094.\n  Batch   600  of  1,094.\n  Batch   650  of  1,094.\n  Batch   700  of  1,094.\n  Batch   750  of  1,094.\n  Batch   800  of  1,094.\n  Batch   850  of  1,094.\n  Batch   900  of  1,094.\n  Batch   950  of  1,094.\n  Batch 1,000  of  1,094.\n  Batch 1,050  of  1,094.\n\nEvaluating...\n  Batch    50  of    235.\n  Batch   100  of    235.\n  Batch   150  of    235.\n  Batch   200  of    235.\n\nTraining Loss: 1.328\nValidation Loss: 0.006\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 7. Evaluate the model results","metadata":{}},{"cell_type":"code","source":"# Push the model to GPU\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\npred_list = []\ncounty = 0\n\n\n# Get predictions for test data, create a list of predictions to evaluate later\nwith torch.no_grad():\n    model.eval()\n    for s,m in zip(test_seq,test_mask):   \n        county += 1\n        preds = model(s.to(device).reshape(1,512), m.to(device).reshape(1,512))\n        preds = preds.detach().cpu().numpy()\n        \n        if county==10000:\n            print('10k')\n        if county==20000:\n            print('20k')\n        \n        pred_list.append(preds[0])","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:36:46.373735Z","iopub.execute_input":"2022-08-31T20:36:46.374293Z","iopub.status.idle":"2022-08-31T20:39:26.126742Z","shell.execute_reply.started":"2022-08-31T20:36:46.374249Z","shell.execute_reply":"2022-08-31T20:39:26.125676Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Pick the higest score for prediction\npred_list = np.argmax(pred_list, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:39:26.133489Z","iopub.execute_input":"2022-08-31T20:39:26.134174Z","iopub.status.idle":"2022-08-31T20:39:26.157926Z","shell.execute_reply.started":"2022-08-31T20:39:26.134133Z","shell.execute_reply":"2022-08-31T20:39:26.157051Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# model's performance\nprint(classification_report(test_y, pred_list))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:40:04.812518Z","iopub.execute_input":"2022-08-31T20:40:04.812904Z","iopub.status.idle":"2022-08-31T20:40:04.837341Z","shell.execute_reply.started":"2022-08-31T20:40:04.812872Z","shell.execute_reply":"2022-08-31T20:40:04.836374Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.59      0.93      0.73      3748\n           1       0.00      0.00      0.00       326\n           2       0.51      0.33      0.40      1641\n           3       0.50      0.12      0.20       947\n           4       0.61      0.24      0.34       838\n\n    accuracy                           0.58      7500\n   macro avg       0.44      0.32      0.33      7500\nweighted avg       0.54      0.58      0.51      7500\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"# confusion matrix\n\ndf_cm = pd.crosstab(pred_list,test_y,colnames=['Real value'], rownames=['Predicted value'])\nsn.heatmap(df_cm, annot=True, fmt='.5g')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:40:15.700426Z","iopub.execute_input":"2022-08-31T20:40:15.701206Z","iopub.status.idle":"2022-08-31T20:40:15.999600Z","shell.execute_reply.started":"2022-08-31T20:40:15.701168Z","shell.execute_reply":"2022-08-31T20:40:15.998615Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:xlabel='Real value', ylabel='Predicted value'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"### Saving and loading the models","metadata":{}},{"cell_type":"code","source":"#save BERT\n#torch.save(model.state_dict(),'model_state_v3.pth')","metadata":{"execution":{"iopub.status.busy":"2022-08-30T22:34:41.619197Z","iopub.execute_input":"2022-08-30T22:34:41.619874Z","iopub.status.idle":"2022-08-30T22:34:42.454955Z","shell.execute_reply.started":"2022-08-30T22:34:41.619809Z","shell.execute_reply":"2022-08-30T22:34:42.453916Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"# load BERT\nmodel = BERT_Arch(bert)\nmodel.load_state_dict(torch.load('../input/model-state-v3/model_state_v1.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T20:35:52.788907Z","iopub.execute_input":"2022-08-31T20:35:52.789267Z","iopub.status.idle":"2022-08-31T20:35:59.059310Z","shell.execute_reply.started":"2022-08-31T20:35:52.789229Z","shell.execute_reply":"2022-08-31T20:35:59.058396Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 8. Conclusions","metadata":{"execution":{"iopub.status.busy":"2022-08-31T21:12:13.647033Z","iopub.execute_input":"2022-08-31T21:12:13.647406Z","iopub.status.idle":"2022-08-31T21:12:13.672013Z","shell.execute_reply.started":"2022-08-31T21:12:13.647330Z","shell.execute_reply":"2022-08-31T21:12:13.670894Z"}}},{"cell_type":"markdown","source":"I ran the training loop three times in order to get a better result. <br>\nWe can see the model definitely \"learned\" and gets a better score than random prediction.\n\nI see two ways to use the model:\n\n1. Approve any post that comes in and then take only the question that predicted anything that is not 0 (open question), then a human will take a look and decide if the question should be closed. In this case, we can get 12%-33% of type 2/3/4 questions denied and 0% of type 1. The rest will be falsy approved.\n2. Approve type 0 prediction automatically, it will mean that we will lose 7% of good questions and give false approval to about 50% of type 2,3,4 of questions and 100% of type 1. This is the easiest way to implment the model, but will probely have to approve the results before.\n\nI think I will keep training the model and maybe change the drop rate/model feature in order to improve my results, especially in category 1.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}